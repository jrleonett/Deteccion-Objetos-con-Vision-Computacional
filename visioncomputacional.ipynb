{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhTz3uBivTKD6wy8n1j8oM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrleonett/Deteccion-Objetos-con-Vision-Computacional/blob/main/visioncomputacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento de imágenes con YOLO y Visión por Computadora\n",
        "\n",
        "Este proyecto utiliza el modelo YOLO (You Only Look Once) para procesar imágenes y detectar objetos en ellas. El código está dividido en tres fases principales: creación de una carpeta para almacenar resultados, procesamiento de la imagen y descarga de los resultados en un archivo ZIP. Realizado por **José R. Leonett** para la comunidad de peritos forenses digitales de Guatemala www.forensedigital.gt"
      ],
      "metadata": {
        "id": "-pFWHCHdJfSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Módulo 1: Carga del modelo YOLO y creación de la carpeta \"EVIDENCIAS\"\n",
        "%%capture\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Crear la carpeta \"EVIDENCIAS\" si no existe\n",
        "if not os.path.exists('EVIDENCIAS'):\n",
        "    os.makedirs('EVIDENCIAS')\n",
        "    print(\"Carpeta 'EVIDENCIAS' creada.\")\n",
        "else:\n",
        "    print(\"La carpeta 'EVIDENCIAS' ya existe.\")\n",
        "\n",
        "# Descargar los archivos de YOLO si no existen\n",
        "if not os.path.exists(\"yolov3.cfg\") or not os.path.exists(\"yolov3.weights\") or not os.path.exists(\"coco.names\"):\n",
        "    print(\"Descargando archivos de YOLO...\")\n",
        "    !wget https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg?raw=true -O yolov3.cfg\n",
        "    !wget https://pjreddie.com/media/files/yolov3.weights\n",
        "    !wget https://github.com/pjreddie/darknet/blob/master/data/coco.names?raw=true -O coco.names\n",
        "    print(\"Archivos de YOLO descargados correctamente.\")\n",
        "\n",
        "# Cargar YOLO\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = f.read().strip().split(\"\\n\")\n",
        "\n",
        "# Definir colores para cada clase\n",
        "class_colors = {\n",
        "    \"person\": (0, 255, 255),        # Amarillo para personas\n",
        "    \"motorbike\": (0, 165, 255),     # Naranja para motocicletas\n",
        "    \"car\": (255, 0, 0),             # Azul para coches\n",
        "    \"bicycle\": (0, 255, 0),         # Verde para bicicletas\n",
        "    \"bus\": (0, 255, 255),           # Amarillo para buses\n",
        "    \"truck\": (0, 0, 255),           # Rojo para camiones\n",
        "    # Agrega más clases y colores aquí según sea necesario\n",
        "\n",
        "    # Vehículos\n",
        "    \"car\": (255, 0, 0),              # Azul para automóviles\n",
        "    \"truck\": (0, 0, 255),            # Rojo para camiones\n",
        "    \"bus\": (0, 255, 255),            # Amarillo para buses\n",
        "    \"motorbike\": (0, 165, 255),      # Naranja para motocicletas\n",
        "    \"bicycle\": (0, 255, 0),          # Verde para bicicletas\n",
        "    \"aeroplane\": (255, 192, 203),    # Rosa para aviones\n",
        "    \"train\": (128, 128, 128),        # Gris para trenes\n",
        "    \"boat\": (0, 0, 128),             # Azul oscuro para barcos\n",
        "\n",
        "    # Personas\n",
        "    \"person\": (0, 255, 255),         # Amarillo para personas\n",
        "    # Nota: YOLO no distingue entre adultos, niños, bebés, etc.\n",
        "\n",
        "    # Animales\n",
        "    \"dog\": (139, 69, 19),            # Marrón para perros\n",
        "    \"cat\": (255, 140, 0),            # Naranja oscuro para gatos\n",
        "    \"horse\": (165, 42, 42),          # Marrón oscuro para caballos\n",
        "    \"sheep\": (192, 192, 192),        # Gris claro para ovejas\n",
        "    \"cow\": (128, 128, 0),            # Oliva para vacas\n",
        "    \"bird\": (0, 255, 127),           # Verde primavera para pájaros\n",
        "\n",
        "    # Objetos cotidianos\n",
        "    \"chair\": (139, 69, 19),          # Marrón para sillas\n",
        "    \"diningtable\": (160, 82, 45),    # Sienna para mesas\n",
        "    \"sofa\": (205, 133, 63),          # Peru para sofás\n",
        "    \"bed\": (222, 184, 135),          # Madera para camas\n",
        "    \"tvmonitor\": (0, 0, 139),        # Azul oscuro para televisores\n",
        "\n",
        "    # Naturaleza\n",
        "    \"pottedplant\": (50, 205, 50),    # Verde lima para plantas en macetas\n",
        "    # Nota: YOLO no detecta montañas, ríos, lagos, etc.\n",
        "\n",
        "    # Alimentos\n",
        "    # Nota: YOLO no detecta frutas, verduras, carnes, etc.\n",
        "\n",
        "    # Deportes\n",
        "    \"sports ball\": (255, 0, 0),      # Rojo para balones de fútbol\n",
        "    # Nota: YOLO no detecta raquetas, bates, tablas de surf, etc.\n",
        "\n",
        "    # Señales y símbolos\n",
        "    \"stop sign\": (255, 0, 0),        # Rojo para señales de tráfico\n",
        "    \"traffic light\": (0, 255, 0),    # Verde para semáforos\n",
        "}\n",
        "\n",
        "print(\"Modelo YOLO cargado y listo para usar.\")"
      ],
      "metadata": {
        "id": "24_e7Q4SCkci",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Módulo 2: Procesamiento de la imagen y generación de resultados\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Verificar si hay imágenes en la carpeta \"EVIDENCIAS\"\n",
        "evidencia_files = os.listdir('EVIDENCIAS')\n",
        "image_extensions = ['.jpg', '.jpeg', '.png']\n",
        "image_name = None\n",
        "\n",
        "# Buscar la primera imagen válida en la carpeta\n",
        "for file in evidencia_files:\n",
        "    if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "        image_name = file\n",
        "        break\n",
        "\n",
        "# Si no se encuentra ninguna imagen, informar y salir\n",
        "if not image_name:\n",
        "    print(\"FAVOR CARGAR ARCHIVO DE IMAGEN A LA CARPETA EVIDENCIAS.\")\n",
        "    exit()  # Salir del programa sin errores\n",
        "\n",
        "# Cargar la imagen\n",
        "image_path = os.path.join('EVIDENCIAS', image_name)\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Si no se puede cargar la imagen, informar y salir\n",
        "if image is None:\n",
        "    print(\"No se pudo cargar la imagen. Asegúrate de que el archivo sea un JPG o PNG válido.\")\n",
        "    exit()\n",
        "\n",
        "# Obtener dimensiones de la imagen\n",
        "height, width, _ = image.shape\n",
        "\n",
        "# Preprocesar la imagen para YOLO\n",
        "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "net.setInput(blob)\n",
        "\n",
        "# Obtener las capas de salida\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers_indices = net.getUnconnectedOutLayers()\n",
        "\n",
        "# Verificar si output_layers_indices es una lista de listas o una lista de enteros\n",
        "if isinstance(output_layers_indices[0], list):\n",
        "    output_layers = [layer_names[i[0] - 1] for i in output_layers_indices]\n",
        "else:\n",
        "    output_layers = [layer_names[i - 1] for i in output_layers_indices]\n",
        "\n",
        "detections = net.forward(output_layers)\n",
        "\n",
        "# Procesar las detecciones\n",
        "conf_threshold = 0.5\n",
        "nms_threshold = 0.4\n",
        "boxes = []\n",
        "confidences = []\n",
        "class_ids = []\n",
        "\n",
        "for output in detections:\n",
        "    for detection in output:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "        if confidence > conf_threshold:\n",
        "            center_x = int(detection[0] * width)\n",
        "            center_y = int(detection[1] * height)\n",
        "            w = int(detection[2] * width)\n",
        "            h = int(detection[3] * height)\n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "            boxes.append([x, y, w, h])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)\n",
        "\n",
        "# Aplicar Non-Maximum Suppression (NMS)\n",
        "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "# Contar objetos detectados por clase\n",
        "object_counts = {}\n",
        "for i in indices:\n",
        "    i = i[0] if isinstance(i, (list, np.ndarray)) else i\n",
        "    class_name = classes[class_ids[i]]\n",
        "    if class_name in object_counts:\n",
        "        object_counts[class_name] += 1\n",
        "    else:\n",
        "        object_counts[class_name] = 1\n",
        "\n",
        "# Dibujar las cajas y etiquetas en la imagen con colores específicos por clase\n",
        "image_detected = image.copy()\n",
        "for i in indices:\n",
        "    i = i[0] if isinstance(i, (list, np.ndarray)) else i\n",
        "    box = boxes[i]\n",
        "    x, y, w, h = box\n",
        "    class_name = classes[class_ids[i]]\n",
        "    confidence = confidences[i]\n",
        "\n",
        "    # Obtener el color para la clase actual\n",
        "    color = class_colors.get(class_name, (0, 255, 0))  # Verde por defecto si no se encuentra la clase\n",
        "\n",
        "    # Dibujar el rectángulo y la etiqueta\n",
        "    cv2.rectangle(image_detected, (x, y), (x + w, y + h), color, 2)\n",
        "    label = f\"{class_name}: {confidence:.2f}\"\n",
        "    cv2.putText(image_detected, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "# Mostrar la imagen original y la imagen con detecciones lado a lado\n",
        "print(\"Imagen original y detecciones:\")\n",
        "combined_image = np.hstack((image, image_detected))  # Combinar imágenes horizontalmente\n",
        "cv2_imshow(combined_image)\n",
        "\n",
        "# Mostrar la cantidad de objetos detectados por clase\n",
        "print(\"\\nCantidad de objetos detectados por clase:\")\n",
        "for class_name, count in object_counts.items():\n",
        "    print(f\"{class_name.upper()}: {count:02d}\")\n",
        "\n",
        "# Guardar la imagen con detecciones\n",
        "output_image_name = image_name.replace(\".jpg\", \"_detectAI.jpg\").replace(\".jpeg\", \"_detectAI.jpg\").replace(\".png\", \"_detectAI.png\")\n",
        "output_image_path = os.path.join('EVIDENCIAS', output_image_name)\n",
        "cv2.imwrite(output_image_path, image_detected)\n",
        "print(f\"\\nImagen con detecciones guardada en {output_image_path}\")\n",
        "\n",
        "# Guardar los conteos en un archivo TXT\n",
        "output_txt_name = image_name.replace(\".jpg\", \"_detectAI.txt\").replace(\".jpeg\", \"_detectAI.txt\").replace(\".png\", \"_detectAI.txt\")\n",
        "output_txt_path = os.path.join('EVIDENCIAS', output_txt_name)\n",
        "with open(output_txt_path, 'w') as f:\n",
        "    f.write(\"Cantidad de objetos detectados por clase:\\n\")\n",
        "    for class_name, count in object_counts.items():\n",
        "        f.write(f\"{class_name.upper()}: {count:02d}\\n\")\n",
        "print(f\"Conteos guardados en {output_txt_path}\")"
      ],
      "metadata": {
        "id": "YTSuPPOzHT7I",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fase 3: Descargar los resultados en un archivo ZIP\n",
        "\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# Crear un archivo ZIP con las imágenes de la carpeta \"EVIDENCIAS\"\n",
        "zip_path = 'EVIDENCIAS.zip'\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, dirs, files_in_folder in os.walk('EVIDENCIAS'):\n",
        "        for file in files_in_folder:\n",
        "            file_path = os.path.join(root, file)\n",
        "            zipf.write(file_path, arcname=file)\n",
        "\n",
        "# Descargar el archivo ZIP\n",
        "files.download(zip_path)\n",
        "print(f\"Archivo {zip_path} descargado.\")"
      ],
      "metadata": {
        "id": "G_8DpghgZcHU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}