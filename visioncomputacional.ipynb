{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBtqiga/l2nzcg1nDGVFF8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrleonett/visioncomputacional/blob/main/visioncomputacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento de imágenes con YOLO y Visión por Computadora\n",
        "\n",
        "Este proyecto utiliza el modelo YOLO (You Only Look Once) para procesar imágenes y detectar objetos en ellas. El código está dividido en tres fases principales: creación de una carpeta para almacenar resultados, procesamiento de la imagen y descarga de los resultados en un archivo ZIP. Realizado por **José R. Leonett** para la comunidad de peritos forenses digitales de Guatemala www.forensedigital.gt"
      ],
      "metadata": {
        "id": "-pFWHCHdJfSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fase 1: Carga de variables y creación de la carpeta \"EVIDENCIA\"\n",
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "pip install mxnet gluoncv matplotlib\n",
        "\n",
        "# Crear la carpeta \"EVIDENCIA\"\n",
        "if not os.path.exists('EVIDENCIA'):\n",
        "    os.makedirs('EVIDENCIA')\n",
        "\n",
        "print(\"Carpeta 'EVIDENCIA' creada.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "24_e7Q4SCkci",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fase 2: Procesamiento de la imagen y detección de objetos\n",
        "# Cargar YOLO\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = f.read().strip().split(\"\\n\")\n",
        "\n",
        "# Cargar la imagen\n",
        "uploaded = files.upload()\n",
        "image_name = next(iter(uploaded))\n",
        "image = cv2.imread(image_name)\n",
        "\n",
        "# Obtener dimensiones de la imagen\n",
        "height, width, _ = image.shape\n",
        "\n",
        "# Preprocesar la imagen para YOLO\n",
        "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "net.setInput(blob)\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "detections = net.forward(output_layers)\n",
        "\n",
        "# Procesar las detecciones\n",
        "conf_threshold = 0.5\n",
        "nms_threshold = 0.4\n",
        "boxes = []\n",
        "confidences = []\n",
        "class_ids = []\n",
        "\n",
        "for output in detections:\n",
        "    for detection in output:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "        if confidence > conf_threshold:\n",
        "            center_x = int(detection[0] * width)\n",
        "            center_y = int(detection[1] * height)\n",
        "            w = int(detection[2] * width)\n",
        "            h = int(detection[3] * height)\n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "            boxes.append([x, y, w, h])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)\n",
        "\n",
        "# Aplicar Non-Maximum Suppression (NMS)\n",
        "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "# Dibujar las cajas y etiquetas en la imagen\n",
        "for i in indices:\n",
        "    i = i[0]\n",
        "    box = boxes[i]\n",
        "    x, y, w, h = box\n",
        "    label = f\"{classes[class_ids[i]]}: {confidences[i]:.2f}\"\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Mostrar la imagen con las detecciones\n",
        "cv2_imshow(image)\n",
        "\n",
        "# Guardar la imagen procesada en la carpeta \"EVIDENCIA\"\n",
        "output_image_path = os.path.join('EVIDENCIA', 'imagen_procesada.jpg')\n",
        "cv2.imwrite(output_image_path, image)\n",
        "print(f\"Imagen procesada guardada en {output_image_path}\")"
      ],
      "metadata": {
        "id": "YTSuPPOzHT7I",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fase 3: Descargar los resultados en un archivo ZIP\n",
        "# Crear un archivo ZIP con los resultados\n",
        "zip_path = 'EVIDENCIA.zip'\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, dirs, files in os.walk('EVIDENCIA'):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file))\n",
        "\n",
        "# Descargar el archivo ZIP\n",
        "files.download(zip_path)\n",
        "print(f\"Archivo {zip_path} descargado.\")"
      ],
      "metadata": {
        "id": "G_8DpghgZcHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zona de resultados"
      ],
      "metadata": {
        "id": "C66ygt2fG-S6"
      }
    }
  ]
}